{
    "mapping_agent": {
        "openai": {
            "main": {
                "system_prompt": "You are a data analysis expert specializing in identifying critical fields in SaaS industry datasets. Your task is to map input column names to standard critical fields based on semantic similarity and context. Pay special attention to mandatory fields marked with **.",
                "user_prompt_template": "Map the following input columns to these critical fields:\n\nMandatory Fields (marked with **):\n- CUST_ID** (customer identifier)\n- DATE** (date/timestamp field)\n- REVENUE** (revenue/amount field)\n- TARGET** (target variable for prediction)\n\nOptional Fields:\n- PROD_ID (product identifier)\n\nInput columns: {columns}\n\nProvide the mapping in JSON format with these exact keys: 'cust_id', 'prod_id', 'date', 'revenue', 'target'. Use null if no suitable match is found.\n\nExample response format:\n{{\n    \"cust_id\": \"customer_identifier\",\n    \"prod_id\": null,\n    \"date\": \"transaction_date\",\n    \"revenue\": \"amount\",\n    \"target\": \"churn_flag\"\n}}\n\nNote: Mandatory fields (cust_id, date, revenue, target) must be mapped. Optional fields can be null."
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following field mapping:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "data_type_suggester": {
        "openai": {
            "main": {
                "system_prompt": "You are a data type expert specializing in preparing data for machine learning models. Your task is to analyze column data types and suggest appropriate conversions, focusing on:\n1. Converting ID columns to text\n2. Standardizing date columns to yyyy-mm format\n3. Suggesting any other necessary type conversions for optimal model performance.",
                "user_prompt_template": "Analyze the following DataFrame information and provide data type conversion instructions:\n\nColumn Data Types:\n{data_info['dtypes']}\n\nSample Values:\n{data_info['sample_values']}\n\nUnique Value Counts:\n{data_info['unique_counts']}\n\nNull Counts:\n{data_info['null_counts']}\n\nProvide conversion instructions in JSON format with these sections:\n1. 'conversions': Numbered list of specific conversion steps\n2. 'validations': List of validation checks to perform after conversion\n\nExample response format:\n{\n    \"conversions\": [\n        \"1. Convert 'customer_id' to string type using df['customer_id'] = df['customer_id'].astype(str)\",\n        \"2. Convert 'transaction_date' to datetime and format as yyyy-mm using pd.to_datetime() and dt.strftime('%Y-%m')\"\n    ],\n    \"validations\": [\n        \"Verify 'customer_id' contains no null values\"\n    ]\n}"
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following data type conversion instructions:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "code_generator": {
        "openai": {
            "main": {
                "system_prompt": "You are a Python code generator specializing in data preprocessing and type conversion tasks. Your role is to generate clean, efficient, and safe Python code that can be executed directly.",
                "user_prompt_template": "Generate Python code to implement the following data preprocessing instructions:\n\nInstructions:\n{instructions}\n\nDataFrame Information:\n{df_info}\n\nPrevious Error (if any): {error_message}\n\nRequirements:\n1. Code should work with a pandas DataFrame named 'df'\n2. Handle errors gracefully with try-except blocks\n3. Preserve original data where possible\n4. Follow pandas best practices\n5. No print statements or comments\n6. Return the modified DataFrame\n\nGenerate production-ready Python code that implements these instructions."
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following generated code:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "categorical_feature_handler": {
        "openai": {
            "main": {
                "system_prompt": "You are a feature engineering expert specializing in categorical data processing. Your task is to analyze categorical columns and suggest appropriate encoding strategies based on cardinality and data characteristics. Follow these rules:\n1. Use one-hot encoding for low cardinality (<=10 unique values)\n2. Use label encoding for medium cardinality (10-50 unique values)\n3. Ignore high cardinality columns (>50 unique values)\n4. Consider special handling for missing values",
                "user_prompt_template": "Analyze the following categorical column information and provide encoding instructions:\n\nCategorical Columns: {categorical_info['categorical_columns']}\n\nCardinality:\n{categorical_info['cardinality']}\n\nSample Values:\n{categorical_info['sample_values']}\n\nNull Counts:\n{categorical_info['null_counts']}\n\nProvide encoding instructions in JSON format with these sections:\n1. 'encodings': Numbered list of specific encoding steps\n2. 'validations': List of validation checks to perform after encoding\n\nExample response format:\n{\n    \"encodings\": [\n        \"1. Apply one-hot encoding to 'category' column (8 unique values)\",\n        \"2. Apply label encoding to 'status' column (15 unique values)\",\n        \"3. Skip 'description' column (high cardinality: 100+ values)\"\n    ],\n    \"validations\": [\n        \"Verify one-hot encoded columns are binary (0/1)\",\n        \"Ensure no missing values in encoded columns\"\n    ]\n}"
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following categorical encoding instructions:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "data_splitter": {
        "openai": {
            "main": {
                "system_prompt": "You are a Python expert specializing in data splitting strategies. Generate executable Python code that splits a pandas DataFrame into train, validation, and inference sets based on data characteristics.",
                "user_prompt_template": "Generate Python code to split the following dataset:\n\nData Info:\n{data_info}\n\nSplitting Rules:\n1. If time series data (has_date=True):\n   - Use last month for inference set\n   - Use previous {validation_window} months for validation\n   - Use remaining months for training\n\n2. If non-time series data:\n   - If missing target values exist:\n     * Use records with missing target as inference set\n     * Split remaining records 80-20 for train-validation\n   - If no missing target values:\n     * Random 70-20-10 split for train-validation-inference\n\nCustom Instructions: {manual_instructions}\n\nRequirements:\n1. Input DataFrame is named 'df'\n2. Output must be three DataFrames: train_df, valid_df, infer_df\n3. Use pandas and numpy (already imported as pd and np)\n4. Include clear explanation of chosen strategy\n\nProvide response in JSON format:\n{\n    \"code\": \"<python code here>\",\n    \"explanation\": \"Clear explanation of which splitting strategy was used and why\"\n}"
            }
        }
    },
    "model_trainer": {
        "openai": {
            "main": {
                "system_prompt": "You are a Python ML expert specializing in training classification models. Generate executable Python code that trains a model, handles class imbalance, and returns performance metrics.",
                "user_prompt_template": "Generate Python code to train a {model_name} model with the following specifications:\n\nData Info:\n{data_info}\n\nCustom Instructions: {custom_instructions}\n\nRequirements:\n1. Input DataFrames are named 'train_df' and 'valid_df'\n2. Handle class imbalance appropriately\n3. Return these variables:\n   - metrics: dict with 'auc', 'precision', 'recall', 'f1', 'confusion_matrix'\n   - training_time: str (e.g., '45s')\n   - model_params: dict of final parameters\n4. Use pandas and numpy (already imported as pd and np)\n5. Import only required model libraries\n\nProvide response in JSON format:\n{\n    \"code\": \"<python code here>\",\n    \"explanation\": \"Clear explanation of training approach and handling of class imbalance\"\n}"
            }
        }
    }
} 